"""–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑ —É–∑–ª–æ–≤ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏."""

from rag.ontology_loader import OntologyLoader
from rag.text_transformer import TextTransformer
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ (–∏–∑–º–µ–Ω–∏—Ç–µ –ø–æ–¥ —Å–≤–æ–∏ —Ñ–∞–π–ª—ã)
ONTOLOGY_FILES = [
    r"c:\Users\just_\Downloads\graph(5).json",
    r"c:\Users\just_\Downloads\graph (2).json"
]

def print_separator(title: str = "", char: str = "=", width: int = 80):
    """–ü–µ—á–∞—Ç–∞–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º."""
    if title:
        padding = (width - len(title) - 2) // 2
        print(f"\n{char * padding} {title} {char * padding}")
    else:
        print(char * width)

def view_node_examples():
    """–ü—Ä–æ—Å–º–æ—Ç—Ä –ø—Ä–∏–º–µ—Ä–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤ —É–∑–ª–æ–≤."""
    
    print_separator("–ü–†–û–°–ú–û–¢–† –ü–†–ò–ú–ï–†–û–í –¢–ï–ö–°–¢–û–í –ò–ó –û–ù–¢–û–õ–û–ì–ò–ò")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–Ω—Ç–æ–ª–æ–≥–∏–π
    print("\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –æ–Ω—Ç–æ–ª–æ–≥–∏–π...")
    loader = OntologyLoader()
    loader.load_multiple_files(ONTOLOGY_FILES)
    
    nodes = loader.get_all_nodes()
    edges = loader.get_all_edges()
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —É–∑–ª–æ–≤: {len(nodes)}")
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–≤—è–∑–µ–π: {len(edges)}\n")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞
    transformer = TextTransformer(loader)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —É–∑–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç—ã
    print("üîÑ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —É–∑–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç—ã...")
    node_texts = transformer.transform_all_nodes()
    
    print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(node_texts)}\n")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —É–∑–ª–æ–≤
    print_separator("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –¢–ò–ü–ê–ú –£–ó–õ–û–í")
    
    type_counts = {}
    for node in nodes:
        node_data = node.get('data', {})
        labels = node_data.get('labels', [])
        
        node_type = None
        if 'http://www.w3.org/2002/07/owl#Class' in labels:
            node_type = 'Class'
        elif 'http://www.w3.org/2002/07/owl#NamedIndividual' in labels:
            node_type = 'Object'
        elif 'http://www.w3.org/2002/07/owl#DatatypeProperty' in labels:
            node_type = 'DatatypeProperty'
        elif 'http://www.w3.org/2002/07/owl#ObjectProperty' in labels:
            node_type = 'ObjectProperty'
        else:
            node_type = 'Unknown'
        
        type_counts[node_type] = type_counts.get(node_type, 0) + 1
    
    for node_type, count in sorted(type_counts.items()):
        print(f"  {node_type}: {count}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤
    print_separator("–ü–†–ò–ú–ï–†–´ –¢–ï–ö–°–¢–û–í –£–ó–õ–û–í")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –ø—Ä–∏–º–µ—Ä–æ–≤
    print(f"\nüìù –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ {len(node_texts)}:\n")
    
    for i, text in enumerate(node_texts[:5], 1):
        print_separator(f"–ü—Ä–∏–º–µ—Ä {i}", char="-", width=60)
        print(text)
        print(f"\n–î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {text.count(chr(10)) + 1}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —É–∑–ª–æ–≤
    print_separator("–ü–†–ò–ú–ï–†–´ –ü–û –¢–ò–ü–ê–ú –£–ó–õ–û–í")
    
    examples_by_type = {}
    for i, node in enumerate(nodes):
        node_data = node.get('data', {})
        labels = node_data.get('labels', [])
        
        node_type = None
        if 'http://www.w3.org/2002/07/owl#Class' in labels:
            node_type = 'Class'
        elif 'http://www.w3.org/2002/07/owl#NamedIndividual' in labels:
            node_type = 'Object'
        elif 'http://www.w3.org/2002/07/owl#DatatypeProperty' in labels:
            node_type = 'DatatypeProperty'
        elif 'http://www.w3.org/2002/07/owl#ObjectProperty' in labels:
            node_type = 'ObjectProperty'
        else:
            node_type = 'Unknown'
        
        if node_type not in examples_by_type:
            examples_by_type[node_type] = []
        
        if len(examples_by_type[node_type]) < 2:  # –ü–æ 2 –ø—Ä–∏–º–µ—Ä–∞ –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
            text = transformer.node_to_text(node)
            if text.strip():
                examples_by_type[node_type].append(text)
    
    for node_type, examples in sorted(examples_by_type.items()):
        if examples:
            print_separator(f"–¢–∏–ø: {node_type}", char="-", width=60)
            for j, example in enumerate(examples, 1):
                print(f"\n–ü—Ä–∏–º–µ—Ä {j}:")
                print(example[:500] + ("..." if len(example) > 500 else ""))
                print()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–∞–º—ã–µ –¥–ª–∏–Ω–Ω—ã–µ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã
    print_separator("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –î–õ–ò–ù–ï –¢–ï–ö–°–¢–û–í")
    
    text_lengths = [(len(text), i, text[:100]) for i, text in enumerate(node_texts)]
    text_lengths.sort()
    
    print("\nüìè –°–∞–º—ã–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã:")
    for length, idx, preview in text_lengths[:3]:
        print(f"  –£–∑–µ–ª {idx}: {length} —Å–∏–º–≤–æ–ª–æ–≤ - {preview}...")
    
    print("\nüìè –°–∞–º—ã–µ –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã:")
    for length, idx, preview in text_lengths[-3:]:
        print(f"  –£–∑–µ–ª {idx}: {length} —Å–∏–º–≤–æ–ª–æ–≤ - {preview}...")
    
    # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞
    avg_length = sum(len(text) for text in node_texts) / len(node_texts) if node_texts else 0
    print(f"\nüìä –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {avg_length:.1f} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä
    print_separator("–ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –ü–†–û–°–ú–û–¢–†")
    print("\n–ö–æ–º–∞–Ω–¥—ã:")
    print("  - –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä —É–∑–ª–∞ (0-{}) –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –µ–≥–æ —Ç–µ–∫—Å—Ç–∞".format(len(node_texts) - 1))
    print("  - –í–≤–µ–¥–∏—Ç–µ 's <—Ç–µ–∫—Å—Ç>' –¥–ª—è –ø–æ–∏—Å–∫–∞ —É–∑–ª–æ–≤ –ø–æ —Ç–µ–∫—Å—Ç—É")
    print("  - –í–≤–µ–¥–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞")
    
    while True:
        try:
            user_input = input("\n>>> ").strip()
            
            if user_input.lower() == 'q':
                break
            
            # –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É
            if user_input.lower().startswith('s '):
                search_term = user_input[2:].strip().lower()
                if not search_term:
                    print("‚ùå –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Å–ª–µ 's '")
                    continue
                
                print(f"\nüîç –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É: '{search_term}'")
                found_count = 0
                for idx, text in enumerate(node_texts):
                    if search_term in text.lower():
                        found_count += 1
                        if found_count <= 5:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                            print_separator(f"–ù–∞–π–¥–µ–Ω —É–∑–µ–ª {idx}", char="-", width=60)
                            print(text[:300] + ("..." if len(text) > 300 else ""))
                
                if found_count == 0:
                    print("‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                elif found_count > 5:
                    print(f"\n... –∏ –µ—â–µ {found_count - 5} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –£—Ç–æ—á–Ω–∏—Ç–µ –ø–æ–∏—Å–∫.")
                else:
                    print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {found_count}")
                continue
            
            # –ü—Ä–æ—Å–º–æ—Ç—Ä –ø–æ –Ω–æ–º–µ—Ä—É
            node_idx = int(user_input)
            if 0 <= node_idx < len(node_texts):
                print_separator(f"–£–∑–µ–ª {node_idx}", char="-", width=60)
                print(node_texts[node_idx])
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —É–∑–ª–∞
                print("\nüìã –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —É–∑–ª–∞ (JSON, –ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤):")
                node = nodes[node_idx]
                node_json = json.dumps(node, ensure_ascii=False, indent=2)
                print(node_json[:500] + ("..." if len(node_json) > 500 else ""))
            else:
                print(f"‚ùå –ù–æ–º–µ—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 0 –¥–æ {len(node_texts) - 1}")
        except ValueError:
            print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ, 's <—Ç–µ–∫—Å—Ç>' –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–ª–∏ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞")
        except KeyboardInterrupt:
            print("\n\nüëã –í—ã—Ö–æ–¥...")
            break
    
    print_separator("–ö–û–ù–ï–¶ –ü–†–û–°–ú–û–¢–†–ê")


if __name__ == "__main__":
    try:
        view_node_examples()
    except FileNotFoundError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω - {e}")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –æ–Ω—Ç–æ–ª–æ–≥–∏–π –≤ ONTOLOGY_FILES")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

