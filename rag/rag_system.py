"""–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å RAG —Å–∏—Å—Ç–µ–º—ã, —Ä–µ–∞–ª–∏–∑—É—é—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤."""

from typing import List, Optional, Tuple
import numpy as np

from .ontology_loader import OntologyLoader
from .text_transformer import TextTransformer
from .embedding_manager import EmbeddingManager
from .retriever import Retriever
from .llm_generator import LLMGenerator
from .llm_generator_api import LLMGeneratorAPI
from neo_graph_test.db.nlp.embeddings import get_embeddings


class RAGSystem:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å RAG —Å–∏—Å—Ç–µ–º—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–Ω—Ç–æ–ª–æ–≥–∏—è–º–∏."""
    
    def __init__(
        self,
        ontology_files: List[str],
        llm_model_name: str = "meta-llama/Llama-3.1-8B-Instruct",
        cache_dir: Optional[str] = None,
        n_nodes: int = 10,
        m_nodes: int = 5,
        use_api: bool = False,
        api_provider: str = "mistral",
        api_key: Optional[str] = None
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã.
        
        Args:
            ontology_files: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ JSON —Ñ–∞–π–ª–∞–º —Å –æ–Ω—Ç–æ–ª–æ–≥–∏—è–º–∏
            llm_model_name: –ò–º—è –º–æ–¥–µ–ª–∏ LLM –∏–∑ HuggingFace (–µ—Å–ª–∏ use_api=False) –∏–ª–∏ –∏–º—è –º–æ–¥–µ–ª–∏ API
            cache_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            n_nodes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
            m_nodes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤ –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            use_api: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ API –≤–º–µ—Å—Ç–æ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            api_provider: –ü—Ä–æ–≤–∞–π–¥–µ—Ä API ('mistral', 'openai', 'anthropic')
            api_key: API –∫–ª—é—á (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è)
        """
        print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã...")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.loader = OntologyLoader()
        self.transformer = None  # –ë—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –æ–Ω—Ç–æ–ª–æ–≥–∏–π
        self.embedding_manager = EmbeddingManager(cache_dir=cache_dir)
        self.retriever = Retriever(self.embedding_manager)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (–ª–æ–∫–∞–ª—å–Ω—ã–π –∏–ª–∏ API)
        if use_api:
            print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ API –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: {api_provider}")
            self.llm_generator = LLMGeneratorAPI(
                provider=api_provider,
                api_key=api_key,
                model=llm_model_name if llm_model_name != "meta-llama/Llama-3.1-8B-Instruct" else None
            )
        else:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ 8-bit –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
            use_8bit = "tiny" in llm_model_name.lower() or "phi" in llm_model_name.lower() or "gpt2" in llm_model_name.lower()
            self.llm_generator = LLMGenerator(model_name=llm_model_name, use_8bit=use_8bit)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
        self.n_nodes = n_nodes
        self.m_nodes = m_nodes
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–Ω—Ç–æ–ª–æ–≥–∏–π
        print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –æ–Ω—Ç–æ–ª–æ–≥–∏–π –∏–∑ {len(ontology_files)} —Ñ–∞–π–ª–æ–≤...")
        self.loader.load_multiple_files(ontology_files)
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —É–∑–ª–æ–≤: {len(self.loader.get_all_nodes())}")
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–≤—è–∑–µ–π: {len(self.loader.get_all_edges())}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
        self.transformer = TextTransformer(self.loader)
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self._prepare_embeddings()
    
    def _prepare_embeddings(self) -> None:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö —É–∑–ª–æ–≤."""
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –∫—ç—à–∞
        if self.embedding_manager.load_cache():
            print("–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫—ç—à–∞")
            return
        
        # –ï—Å–ª–∏ –∫—ç—à–∞ –Ω–µ—Ç, –≤—ã—á–∏—Å–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        print("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —É–∑–ª–æ–≤ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏...")
        node_texts = self.transformer.transform_all_nodes()
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º node.get('id') –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π ID (—ç—Ç–æ URI, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Å–≤—è–∑—è—Ö)
        # –ï—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º data.uri, –∑–∞—Ç–µ–º data.id
        node_ids = []
        for node in self.loader.get_all_nodes():
            node_id = node.get('id') or node.get('data', {}).get('uri') or node.get('data', {}).get('id', '')
            node_ids.append(node_id)
        
        self.embedding_manager.compute_embeddings(node_texts, node_ids)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        self.embedding_manager.save_cache()
    
    def _get_connected_node_indices(self, node_indices: List[int], max_depth: int = 1, verbose: bool = False) -> List[int]:
        """–ù–∞—Ö–æ–¥–∏—Ç –∏–Ω–¥–µ–∫—Å—ã —É–∑–ª–æ–≤, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –¥–∞–Ω–Ω—ã–º–∏ —É–∑–ª–∞–º–∏ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ.
        
        Args:
            node_indices: –°–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤ —É–∑–ª–æ–≤
            max_depth: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–µ–π (1 = —Ç–æ–ª—å–∫–æ –ø—Ä—è–º—ã–µ —Å–≤—è–∑–∏)
            verbose: –í—ã–≤–æ–¥–∏—Ç—å –ª–∏ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤
        """
        connected_indices = set()
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥: –∏–Ω–¥–µ–∫—Å -> ID —É–∑–ª–∞
        index_to_id = {idx: node_id for node_id, idx in self.embedding_manager.node_indices.items()}
        
        if verbose:
            print(f"  üîç –ü–æ–∏—Å–∫ —Å–≤—è–∑–µ–π –¥–ª—è {len(node_indices)} —É–∑–ª–æ–≤...")
        
        for node_idx in node_indices:
            node_id = index_to_id.get(node_idx)
            if not node_id:
                if verbose:
                    print(f"  ‚ö†Ô∏è  –£–∑–µ–ª —Å –∏–Ω–¥–µ–∫—Å–æ–º {node_idx} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –º–∞–ø–ø–∏–Ω–≥–µ")
                continue
            
            if verbose:
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —É–∑–ª–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                node_text = self.retriever.get_node_texts([node_idx])[0] if self.retriever.get_node_texts([node_idx]) else "N/A"
                print(f"  üìå –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–∑–ª–∞ {node_idx}:")
                print(f"     ID: {node_id[:80]}...")
                print(f"     –¢–µ–∫—Å—Ç: {node_text[:100]}...")
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–≤—è–∑–∏ –¥–ª—è —ç—Ç–æ–≥–æ —É–∑–ª–∞
            edges = self.loader.get_edges_for_node(node_id)
            
            if verbose:
                print(f"     –ù–∞–π–¥–µ–Ω–æ —Å–≤—è–∑–µ–π: {len(edges)}")
            
            if len(edges) == 0:
                if verbose:
                    print(f"     ‚ö†Ô∏è  –°–≤—è–∑–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —É–∑–ª–∞ {node_id[:50]}...")
            
            for edge_idx, edge in enumerate(edges):
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–π —É–∑–µ–ª
                source = edge.get('source')
                target = edge.get('target')
                
                if isinstance(source, dict):
                    source_id = source.get('id', '')
                else:
                    source_id = str(source) if source else ''
                
                if isinstance(target, dict):
                    target_id = target.get('id', '')
                else:
                    target_id = str(target) if target else ''
                
                if verbose:
                    edge_data = edge.get('data', {})
                    edge_label = edge_data.get('uri', edge_data.get('labels', ['N/A'])[0] if edge_data.get('labels') else 'N/A')
                    print(f"     –°–≤—è–∑—å {edge_idx + 1}:")
                    print(f"       –¢–∏–ø: {edge_label}")
                    print(f"       Source ID: {source_id[:60]}...")
                    print(f"       Target ID: {target_id[:60]}...")
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º ID —Å–≤—è–∑–∞–Ω–Ω–æ–≥–æ —É–∑–ª–∞
                if source_id == node_id:
                    related_node_id = target_id
                    direction = "outgoing"
                elif target_id == node_id:
                    related_node_id = source_id
                    direction = "incoming"
                else:
                    if verbose:
                        print(f"       ‚ö†Ô∏è  –£–∑–µ–ª –Ω–µ —É—á–∞—Å—Ç–≤—É–µ—Ç –≤ —Å–≤—è–∑–∏ (source={source_id[:30]}, target={target_id[:30]})")
                    continue
                
                if verbose:
                    print(f"       –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {direction}")
                    print(f"       –°–≤—è–∑–∞–Ω–Ω—ã–π —É–∑–µ–ª ID: {related_node_id[:60]}...")
                
                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å —Å–≤—è–∑–∞–Ω–Ω–æ–≥–æ —É–∑–ª–∞
                related_idx = self.embedding_manager.node_indices.get(related_node_id)
                if related_idx is not None:
                    connected_indices.add(related_idx)
                    if verbose:
                        related_text = self.retriever.get_node_texts([related_idx])[0] if self.retriever.get_node_texts([related_idx]) else "N/A"
                        print(f"       ‚úÖ –ù–∞–π–¥–µ–Ω —Å–≤—è–∑–∞–Ω–Ω—ã–π —É–∑–µ–ª {related_idx}: {related_text[:80]}...")
                else:
                    if verbose:
                        print(f"       ‚ö†Ô∏è  –°–≤—è–∑–∞–Ω–Ω—ã–π —É–∑–µ–ª {related_node_id[:50]}... –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∏–Ω–¥–µ–∫—Å–∞—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–∞–∫–æ–π —É–∑–µ–ª –≤–æ–æ–±—â–µ
                        related_node = self.loader.get_node_by_id(related_node_id)
                        if related_node:
                            print(f"       ‚ÑπÔ∏è  –£–∑–µ–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏, –Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö")
                        else:
                            print(f"       ‚ùå –£–∑–µ–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏")
        
        if verbose:
            print(f"  üìä –ò—Ç–æ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(connected_indices)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤")
        
        return list(connected_indices)
    
    def query(self, user_question: str, verbose: bool = True) -> str:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ —Å–∏—Å—Ç–µ–º–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç.
        
        –†–µ–∞–ª–∏–∑—É–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º –∏–∑ –∑–∞–¥–∞–Ω–∏—è:
        1. –í—ã—á–∏—Å–ª—è–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
        2. –ù–∞—Ö–æ–¥–∏—Ç N –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —É–∑–ª–æ–≤
        3. –ù–∞—Ö–æ–¥–∏—Ç —Å–≤—è–∑–∞–Ω–Ω—ã–µ —É–∑–ª—ã —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ–æ–≤—ã–µ —Å–≤—è–∑–∏
        4. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä–≤—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ N —É–∑–ª–æ–≤
        5. –í—ã—á–∏—Å–ª—è–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –ø–µ—Ä–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        6. –ù–∞—Ö–æ–¥–∏—Ç M –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —É–∑–ª–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞
        7. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ N+M —É–∑–ª–æ–≤
        
        Args:
            user_question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            verbose: –í—ã–≤–æ–¥–∏—Ç—å –ª–∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            
        Returns:
            –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å
        """
        if verbose:
            print(f"\n{'='*60}")
            print(f"–ó–∞–ø—Ä–æ—Å: {user_question}")
            print(f"{'='*60}\n")
        
        # –§–∞–∑–∞ 1: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
        if verbose:
            print("–§–∞–∑–∞ 1: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞...")
        query_embedding = get_embeddings(user_question, normalize=True)
        
        # –§–∞–∑–∞ 2: –ü–æ–∏—Å–∫ N —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —É–∑–ª–æ–≤
        if verbose:
            print(f"–§–∞–∑–∞ 2: –ü–æ–∏—Å–∫ {self.n_nodes} –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —É–∑–ª–æ–≤...")
        n_results = self.retriever.retrieve(query_embedding, top_k=self.n_nodes)
        
        if verbose:
            print(f"–ù–∞–π–¥–µ–Ω–æ {len(n_results)} —É–∑–ª–æ–≤:")
            for idx, (node_idx, score, text) in enumerate(n_results, 1):
                # –ü–æ–ª—É—á–∞–µ–º ID —É–∑–ª–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                node_id = {idx: node_id for node_id, idx in self.embedding_manager.node_indices.items()}.get(node_idx, "N/A")
                print(f"  {idx}. –£–∑–µ–ª {node_idx} (—Å—Ö–æ–¥—Å—Ç–≤–æ: {score:.4f})")
                print(f"     ID: {str(node_id)[:80]}...")
                print(f"     –¢–µ–∫—Å—Ç: {text[:100]}...")
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã N —É–∑–ª–æ–≤
        n_node_indices = [idx for idx, _, _ in n_results]
        
        # –§–∞–∑–∞ 2.5: –ü–æ–∏—Å–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
        if verbose:
            print(f"\n–§–∞–∑–∞ 2.5: –ü–æ–∏—Å–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ–æ–≤—ã–µ —Å–≤—è–∑–∏...")
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º {len(n_node_indices)} –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —É–∑–ª–æ–≤:")
            for idx, node_idx in enumerate(n_node_indices[:5], 1):
                node_id = {idx: node_id for node_id, idx in self.embedding_manager.node_indices.items()}.get(node_idx)
                node_text = self.retriever.get_node_texts([node_idx])[0] if self.retriever.get_node_texts([node_idx]) else "N/A"
                print(f"  {idx}. –£–∑–µ–ª {node_idx}: {node_text[:80]}...")
                if node_id:
                    print(f"     ID: {node_id[:80]}...")
        connected_indices = self._get_connected_node_indices(n_node_indices, max_depth=1, verbose=verbose)
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —É–∑–ª—ã
        new_connected_indices = [idx for idx in connected_indices if idx not in n_node_indices]
        
        if verbose:
            print(f"–ù–∞–π–¥–µ–Ω–æ {len(new_connected_indices)} —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ")
            if new_connected_indices:
                for idx, connected_idx in enumerate(new_connected_indices[:3], 1):
                    text = self.retriever.get_node_texts([connected_idx])[0] if self.retriever.get_node_texts([connected_idx]) else ""
                    print(f"  {idx}. –°–≤—è–∑–∞–Ω–Ω—ã–π —É–∑–µ–ª {connected_idx}")
                    if text:
                        print(f"     {text[:100]}...")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —É–∑–ª—ã –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
        n_node_indices = list(set(n_node_indices + new_connected_indices))
        n_node_texts = self.retriever.get_node_texts(n_node_indices)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        if verbose:
            print("\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ N —É–∑–ª–æ–≤...")
        first_answer = self.llm_generator.answer_question(user_question, n_node_texts)
        
        if verbose:
            print(f"–ü–µ—Ä–≤—ã–π –æ—Ç–≤–µ—Ç: {first_answer[:200]}...\n")
        
        # –§–∞–∑–∞ 3: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –ø–µ—Ä–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        if verbose:
            print("–§–∞–∑–∞ 3: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –ø–µ—Ä–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞...")
        answer_embedding = get_embeddings(first_answer, normalize=True)
        
        # –ü–æ–∏—Å–∫ M –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —É–∑–ª–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞
        if verbose:
            print(f"–ü–æ–∏—Å–∫ {self.m_nodes} –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —É–∑–ª–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞...")
        m_results = self.retriever.retrieve(answer_embedding, top_k=self.m_nodes)
        
        if verbose:
            print(f"–ù–∞–π–¥–µ–Ω–æ {len(m_results)} –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —É–∑–ª–æ–≤")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç—ã M —É–∑–ª–æ–≤
        m_node_indices = [idx for idx, _, _ in m_results]
        m_node_texts = self.retriever.get_node_texts(m_node_indices)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º N –∏ M —É–∑–ª—ã (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ)
        all_node_indices = list(set(n_node_indices + m_node_indices))
        all_node_texts = self.retriever.get_node_texts(all_node_indices)
        
        if verbose:
            print(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É–∑–ª–æ–≤ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {len(all_node_texts)}\n")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        if verbose:
            print("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ N+M —É–∑–ª–æ–≤...")
        final_answer = self.llm_generator.answer_question(user_question, all_node_texts)
        
        if verbose:
            print(f"\n{'='*60}")
            print("–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç:")
            print(f"{'='*60}\n")
        
        return final_answer
    
    def get_node_info(self, node_id: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–∞ –ø–æ –µ–≥–æ ID.
        
        Args:
            node_id: ID —É–∑–ª–∞
            
        Returns:
            –¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–∞ –∏–ª–∏ None
        """
        node = self.loader.get_node_by_id(node_id)
        if node:
            return self.transformer.node_to_text(node)
        return None

